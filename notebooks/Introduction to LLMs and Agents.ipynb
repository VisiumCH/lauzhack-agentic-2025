{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LLMs and Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to our workshop! In this session, we'll explore how to build AI-powered applications using **LangChain**, a popular framework for developing applications with Large Language Models (LLMs). We'll start with a simple chatbot and then enhance it with a multi-agent framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to set up our environment. We'll use OpenAI's models, so we need an API key. You can define your `OPENAI_API_KEY` in the `.env` file.\n",
    "\n",
    "The code retrieve the key and sets some global configurations:\n",
    "- `LLM_MODEL`: The specific model we'll use\n",
    "- `LLM_TEMPERATURE`: Controls randomness in responses (0 means very deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_TEMPERATURE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A simple edit of the original yfinance tool to make it less restrictive.\"\"\"\n",
    "\n",
    "from typing import Iterable, Optional, Type\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForToolRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from requests.exceptions import HTTPError, ReadTimeout\n",
    "from urllib3.exceptions import ConnectionError\n",
    "\n",
    "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
    "\n",
    "\n",
    "class YahooFinanceNewsInput(BaseModel):\n",
    "    \"\"\"Input for the YahooFinanceNews tool.\"\"\"\n",
    "\n",
    "    query: str = Field(description=\"company ticker query to look up\")\n",
    "\n",
    "\n",
    "class YahooFinanceNewsTool(BaseTool):\n",
    "    \"\"\"Tool that searches financial news on Yahoo Finance.\"\"\"\n",
    "\n",
    "    name: str = \"yahoo_finance_news\"\n",
    "    description: str = (\n",
    "        \"Useful for when you need to find financial news \"\n",
    "        \"about a public company. \"\n",
    "        \"Input should be a company ticker. \"\n",
    "        \"For example, AAPL for Apple, MSFT for Microsoft.\"\n",
    "    )\n",
    "    top_k: int = 10\n",
    "    \"\"\"The number of results to return.\"\"\"\n",
    "\n",
    "    args_schema: Type[BaseModel] = YahooFinanceNewsInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Use the Yahoo Finance News tool.\n",
    "\n",
    "        Args:\n",
    "            query: Company ticker symbol (e.g., 'AAPL' for Apple).\n",
    "            run_manager: Optional callback manager.\n",
    "\n",
    "        Returns:\n",
    "            str: Formatted news results or error message.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import yfinance\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import yfinance python package. \"\n",
    "                \"Please install it with `pip install yfinance`.\"\n",
    "            )\n",
    "        company = yfinance.Ticker(query)\n",
    "\n",
    "        try:\n",
    "            if company.isin is None:\n",
    "                return f\"Company ticker {query} not found.\"\n",
    "        except (HTTPError, ReadTimeout, ConnectionError):\n",
    "            return f\"Company ticker {query} not found.\"\n",
    "\n",
    "        links = []\n",
    "\n",
    "        try:\n",
    "            links = [\n",
    "                n[\"content\"][\"canonicalUrl\"][\"url\"]\n",
    "                for n in company.news\n",
    "                if n[\"content\"][\"contentType\"] == \"STORY\"\n",
    "            ]\n",
    "            # print(links)\n",
    "\n",
    "        except (HTTPError, ReadTimeout, ConnectionError):\n",
    "            if not links:\n",
    "                return f\"No news found for company that searched with {query} ticker.\"\n",
    "        if not links:\n",
    "            return f\"No news found for company that searched with {query} ticker.\"\n",
    "        loader = WebBaseLoader(web_paths=links)\n",
    "        docs = loader.load()\n",
    "        result = self._format_results(docs, query)\n",
    "        if not result:\n",
    "            return f\"No news found for company that searched with {query} ticker.\"\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_results(docs: Iterable[Document], query: str) -> str:\n",
    "        doc_strings = [\n",
    "            \"\\n\".join([doc.metadata[\"title\"], doc.metadata.get(\"description\", \"\")])\n",
    "            for doc in docs\n",
    "            # if query in doc.metadata.get(\"description\", \"\")\n",
    "            # or query in doc.metadata[\"title\"]\n",
    "        ]\n",
    "        return \"\\n\\n\".join(doc_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [YahooFinanceNewsTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = YahooFinanceNewsTool()\n",
    "tool.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with creating a basic chatbot using **LangChain**. We'll use:\n",
    "- `ChatOpenAI`: The interface to OpenAI's chat models\n",
    "- `SystemMessage`: Defines the bot's behavior and role\n",
    "- `HumanMessage`: Represents user input\n",
    "\n",
    "Our chatbot will act as a Financial Analyst. We'll create it by:\n",
    "1. Instantiating the model\n",
    "2. Defining a system prompt that sets the bot's role\n",
    "3. Sending a user query and getting a response with `.invoke()`\n",
    "\n",
    "This demonstrates the basic pattern of LLM interactions: prompt → response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatOpenAI instance with the LLM model and temperature\n",
    "base_model = ChatOpenAI(model=LLM_MODEL, temperature=LLM_TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = \"\"\"\n",
    "You are a Financial Analyst. Do your best to help the client with their request based on your expertise. Give a clear and succint financial strategy with precise numbers and allocations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request from the client\n",
    "request = \"I'm 25 year old and have $1,000 saved. which US stocks should I invest into?\"\n",
    "\n",
    "# Message list for the base model\n",
    "messages = [\n",
    "    SystemMessage(BASE_PROMPT),\n",
    "    HumanMessage(request),\n",
    "]\n",
    "\n",
    "# Invoke the model with the messages\n",
    "response = base_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Agent with Yahoo Finance News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tools and a dictionnary of tool functions by name\n",
    "tools = [YahooFinanceNewsTool()]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = (\n",
    "    # \"I'm 25 year old and have $1,000 saved. which US stocks should I invest into?\"\n",
    "    \"How does Microsoft feels today comparing with Nvidia?\"\n",
    ")\n",
    "FINANCE_TOOL_PROMPT = \"\"\"\n",
    "You are a Financial Analyst. The client will ask you a question, and you will give them financial advice.\n",
    "Then based on the stocks you advise, use the Yahoo Finance tool to get news if it's worth buying currently.\n",
    "Give clear investment advice at the end. Do not assess risk.\n",
    "\"\"\"\n",
    "\n",
    "task_str = f\"User question: {user_question}\"\n",
    "\n",
    "fa_model = base_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message list for the financial assistant model\n",
    "messages = [\n",
    "    SystemMessage(FINANCE_TOOL_PROMPT),\n",
    "    HumanMessage(task_str),\n",
    "]\n",
    "\n",
    "# Invoke the financial assistant model with the messages\n",
    "fa_output = fa_model.invoke(messages)\n",
    "\n",
    "# If the financial assistant model made tool calls, invoke the tool\n",
    "if fa_output.tool_calls:\n",
    "    news_list = []\n",
    "    id_list = []\n",
    "    for tool_call in fa_output.tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        news = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "        display(Markdown(f\"**Yahoo Finance news**: {news}\"))\n",
    "\n",
    "        news_list.append(news)\n",
    "        id_list.append(tool_call[\"id\"])\n",
    "\n",
    "    # Combine the retrieved documents into a single string\n",
    "    news_str = news\n",
    "    # Message list with the retrieved documents for the base model\n",
    "    messages = [\n",
    "        SystemMessage(FINANCE_TOOL_PROMPT),\n",
    "        HumanMessage(task_str),\n",
    "        fa_output,\n",
    "        *[\n",
    "            ToolMessage(news_str, tool_call_id=tool_call_id)\n",
    "            for (news_str, tool_call_id) in zip(news_list, id_list)\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    # Invoke the base model with the messages\n",
    "    fa_output_final = fa_model.invoke(messages)\n",
    "\n",
    "\n",
    "Markdown(fa_output_final.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a simple agentic system consisting of three agents using LangChain.\n",
    "This system will help us perform a more elaborate financial analysis by including:\n",
    "\n",
    "- Client Interface Agent: Rephrases the user’s prompt to improve the quality of the financial analyst’s response.\n",
    "\n",
    "- Financial Analyst: Similar to the first part; provides financial advice based on the refined prompt.\n",
    "\n",
    "- Risk Advisor: Assesses the risk associated with the advice given by the financial analyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Workflow and State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangGraph** helps us manage communication between our agents efficiently by defining a `State` class that will convey information from a node to the next during execution.\n",
    "\n",
    "We keep our state simple by including only two attributes, but it's possible to include more:\n",
    "- Messages: The ongoing conversation chain\n",
    "- Analyses: Research findings from our agents\n",
    "\n",
    "We use Python's dataclasses with special annotations (`Annotated`) to define how the state attributes should be updated throughout the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class State:\n",
    "    \"\"\"Graph state for the financial analysis workflow.\"\"\"\n",
    "\n",
    "    messages: Annotated[list[BaseMessage], add_messages] = field(default_factory=list)\n",
    "    yahoo_finance_news: Annotated[list[BaseMessage], add_messages] = field(\n",
    "        default_factory=list\n",
    "    )\n",
    "    risk_analysis: Annotated[list[BaseMessage], add_messages] = field(\n",
    "        default_factory=list\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = \"\"\"\n",
    "You are going to reformulate the user question to make it more precise for a financial analyst.\n",
    "\"\"\"\n",
    "# Create the orchestrator model model from the base model with tool binding\n",
    "bra_model = base_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CIA orchestrator with the next node options\n",
    "def orchestrator_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"financial_analyst\", \"risk_analyst\", END]]:\n",
    "    \"\"\"Orchestrator that generates a plan for the financial analysis.\"\"\"\n",
    "    display(Markdown(f\"**Client request received**: {state.messages[-1].content}\"))\n",
    "\n",
    "    # Message list for the orchestrator model\n",
    "    messages = [\n",
    "        SystemMessage(ORCHESTRATOR_PROMPT),\n",
    "        *state.messages,\n",
    "    ]\n",
    "\n",
    "    # Invoke the CIA model\n",
    "    orchestrator_output = base_model.invoke(messages)\n",
    "\n",
    "    display(Markdown(f\"**CIA Response:** {orchestrator_output.content}\"))\n",
    "\n",
    "    return Command(\n",
    "        # Update the state messages with the CIA response\n",
    "        update={\"messages\": orchestrator_output.content},\n",
    "        # Go to worker nodes if the request is in scope, otherwise end the workflow\n",
    "        goto=[\"financial_analyst\", \"risk_analyst\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial analyst Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINANCE_TOOL_PROMPT = \"\"\"\n",
    "You are a Financial Analyst. The client will ask you a question, and you will give them financial advice.\n",
    "Then based on the stocks you advise, use the Yahoo Finance tool to get news if it's worth buying currently.\n",
    "Give clear investment advice at the end. Do not assess risk.\n",
    "\"\"\"\n",
    "\n",
    "# Create the financial assistant model from the base model with tool binding\n",
    "fa_model = base_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the worker node and the next node options\n",
    "def financial_analyst_node(state: State) -> Command[Literal[\"synthesizer\"]]:\n",
    "    \"\"\"Given a user question, get financial advice from Yahoo Finance news.\"\"\"\n",
    "    display(Markdown(\"**Giving financial advice without risk information**\"))\n",
    "    # Message list for the financial assistant model\n",
    "    messages = [\n",
    "        SystemMessage(FINANCE_TOOL_PROMPT),\n",
    "        *state.messages,\n",
    "    ]\n",
    "\n",
    "    # Invoke the financial assistant model with the messages\n",
    "    fa_output = fa_model.invoke(messages)\n",
    "\n",
    "    # If the financial assistant model made tool calls, invoke the tool\n",
    "    if fa_output.tool_calls:\n",
    "        news_list = []\n",
    "        id_list = []\n",
    "        for tool_call in fa_output.tool_calls:\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            news = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "            # display(Markdown(f\"**Yahoo Finance news**: {news}\"))\n",
    "\n",
    "            news_list.append(news)\n",
    "            id_list.append(tool_call[\"id\"])\n",
    "\n",
    "        # Message list with the retrieved documents for the base model\n",
    "        messages = [\n",
    "            SystemMessage(FINANCE_TOOL_PROMPT),\n",
    "            HumanMessage(task_str),\n",
    "            fa_output,\n",
    "            *[\n",
    "                ToolMessage(news_str, tool_call_id=tool_call_id)\n",
    "                for (news_str, tool_call_id) in zip(news_list, id_list)\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "        # Invoke the base model with the messages\n",
    "        fa_output = fa_model.invoke(messages)\n",
    "\n",
    "    # Update the state analyses with the financial analyst output content and go to the synthesizer node\n",
    "    # NOTE: To update `analyses` you should return a list\n",
    "    return Command(\n",
    "        update={\"yahoo_finance_news\": [fa_output.content]},\n",
    "        goto=\"synthesizer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk analyst Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_ANALYST_PROMPT = \"\"\"\n",
    "You are a Risk Advisor.\n",
    "Evaluate the analyst's advice from a risk perspective. Offer any cautions and ways to reduce risk, don't repeat the analyst's advice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the synthesizer node and the next node options\n",
    "def risk_analyst_node(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"Given the user prompt perform risk analysis.\"\"\"\n",
    "    display(Markdown(\"**Performing risk analysis.**\"))\n",
    "\n",
    "    # Access the previous responses\n",
    "    finance_analysis = state.yahoo_finance_news\n",
    "\n",
    "    # Combine the previous messages into a single string\n",
    "    complete_analyses = \"The financial advisor's analysis:\" + \"\\n\\n---\\n\\n\".join(\n",
    "        finance_analysis\n",
    "    )\n",
    "\n",
    "    # Message list for the risk analyst\n",
    "    messages = [\n",
    "        SystemMessage(RISK_ANALYST_PROMPT),\n",
    "        *state.messages,\n",
    "        AIMessage(complete_analyses),\n",
    "    ]\n",
    "\n",
    "    # Invoke the base model with the messages\n",
    "    risk_analyst_output = base_model.invoke(messages)\n",
    "\n",
    "    # Update the state messages with the risk analyst's output content and go to the synthesizer node\n",
    "    return Command(\n",
    "        update={\"risk_analysis\": [risk_analyst_output.content]},\n",
    "        goto=\"synthesizer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesiser node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTHESISER_PROMPT = \"\"\"\n",
    "Your are a financial analyst, take the general financial analyst's insights and the risk analyst's insights and combine them to generate comprehensive financial advise for the user.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the synthesizer node and the next node options\n",
    "def synthesizer_node(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"Synthesize full report from research analyses.\"\"\"\n",
    "    display(Markdown(\"**Synthesizing messages from the two analysts.**\"))\n",
    "\n",
    "    # Access the previous responses\n",
    "    finance_analysis = state.yahoo_finance_news\n",
    "\n",
    "    risk_analysis = state.risk_analysis\n",
    "\n",
    "    # Combine the research analyses into a single string\n",
    "    financial_analysis_str = \"risk analysis: \" + \"\\n\\n---\\n\\n\".join(\n",
    "        [item.content for item in finance_analysis]\n",
    "    )\n",
    "    risk_analysis_str = \"risk analysis: \" + \"\\n\\n---\\n\\n\".join(\n",
    "        [item.content for item in risk_analysis]\n",
    "    )\n",
    "\n",
    "    # Message list for the RSA model\n",
    "    messages = [\n",
    "        SystemMessage(SYNTHESISER_PROMPT),\n",
    "        AIMessage(financial_analysis_str),\n",
    "        AIMessage(risk_analysis_str),\n",
    "    ]\n",
    "\n",
    "    # Invoke the base model with the messages\n",
    "    synth_output = base_model.invoke(messages)\n",
    "\n",
    "    # Update the state messages with the RSA output content and end the workflow\n",
    "    return Command(\n",
    "        update={\"messages\": synth_output},\n",
    "        goto=END,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Workflow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our nodes and communication flow are defined, we can build the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a state graph builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Define the entry point\n",
    "graph_builder.set_entry_point(\"orchestrator\")\n",
    "\n",
    "# Add the nodes\n",
    "graph_builder.add_node(\"orchestrator\", orchestrator_node)\n",
    "graph_builder.add_node(\"financial_analyst\", financial_analyst_node)\n",
    "graph_builder.add_node(\"risk_analyst\", risk_analyst_node)\n",
    "graph_builder.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "# The edges are defined by the commands !\n",
    "\n",
    "# Compile the workflow\n",
    "app = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our Financial Analyst graph. Note that because the number of `\"worker\"` nodes is generated dynamically, it shows up as a single node in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(app.get_graph().draw_mermaid_png()))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our workflow is built, let's test it! Once again, we can run it with `.invoke()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = (\n",
    "    \"I am a 25 year old and have $1,000 saved. which US stocks should I invest into?\"\n",
    ")\n",
    "\n",
    "# Invoke the workflow with the client request\n",
    "final_state = app.invoke({\"messages\": request})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(final_state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
